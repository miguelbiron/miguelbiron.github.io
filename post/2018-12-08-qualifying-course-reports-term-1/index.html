<!DOCTYPE html>

<html lang="en-us">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="format-detection" content="telephone=no"/>

    <title>Miguel Biron-Lattes</title>
    
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#FF3DB4">
    <meta name="theme-color" content="#ffffff">

    
    
    
    <link rel="stylesheet" href="/css/main.min.94c0b31e181fb13073f914380380d6abf8ab82fc141699e33ddef9b624377ae3.css"/>
    
    
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/xcode.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

    
    
    

    
    <link type="text/css" rel="stylesheet" href="/css/custom.css">
 
    
    
</head>
    <body>
        
<nav>
  <header>
    <div class="site-title">
        <a href="/">Miguel Biron-Lattes</a>
    </div>  
</header>
  <div class="nav-menu">
  
    <a class="color-link nav-link" href="/docs/resume_miguel_biron-lattes.pdf">Resume</a>
  
    <a class="color-link nav-link" href="/post/">Old blog</a>
  
  
</div>
<footer class="footer">
	<div class="social-icons">
        
    <a class="social-icon" href="mailto:miguel.biron@stat.ubc.ca" target="_blank" rel="noopener" title="Email">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M25.2794292,5.59128519 L14,16.8707144 L2.72057081,5.59128519 C3.06733103,5.30237414 3.51336915,5.12857603 4,5.12857603 L24,5.12857603 C24.4866308,5.12857603 24.932669,5.30237414 25.2794292,5.59128519 Z M25.9956978,6.99633695 C25.998551,7.04004843 26,7.08414302 26,7.12857603 L26,20.871424 C26,21.0798433 25.9681197,21.2808166 25.9089697,21.4697335 L18.7156355,14.2763993 L25.9956978,6.99633695 Z M24.9498374,22.6319215 C24.6672737,22.7846939 24.3437653,22.871424 24,22.871424 L4,22.871424 C3.5268522,22.871424 3.09207889,22.7071233 2.74962118,22.432463 L10.0950247,15.0870594 L13.9848068,18.9768415 L14.1878486,18.7737996 L14.2030419,18.7889929 L17.6549753,15.3370594 L24.9498374,22.6319215 Z M2.00810114,21.0526627 C2.00273908,20.9929669 2,20.9325153 2,20.871424 L2,7.12857603 C2,7.08414302 2.00144896,7.04004843 2.00430222,6.99633695 L9.03436454,14.0263993 L2.00810114,21.0526627 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    

    

    

    
    <a class="social-icon" href="https://linkedin.com/in/miguelbiron" target="_blank" rel="noopener" title="LinkedIn">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M2,3.654102 C2,2.69908141 2.79442509,1.92397846 3.77383592,1.92397846 L24.2261641,1.92397846 C25.2058917,1.92397846 26,2.69908141 26,3.654102 L26,24.3462148 C26,25.3015521 25.2058917,26.0760215 24.2261641,26.0760215 L3.77383592,26.0760215 C2.79442509,26.0760215 2,25.3015521 2,24.3465315 L2,3.65378524 L2,3.654102 Z M9.27526132,22.1415901 L9.27526132,11.2356668 L5.65030092,11.2356668 L5.65030092,22.1415901 L9.27557808,22.1415901 L9.27526132,22.1415901 Z M7.46341463,9.74691162 C8.72727273,9.74691162 9.51409566,8.90940767 9.51409566,7.86284447 C9.49033893,6.79252455 8.72727273,5.97846056 7.48748812,5.97846056 C6.24675325,5.97846056 5.43649034,6.79252455 5.43649034,7.86284447 C5.43649034,8.90940767 6.22299652,9.74691162 7.4396579,9.74691162 L7.46309788,9.74691162 L7.46341463,9.74691162 Z M11.2815965,22.1415901 L14.9062401,22.1415901 L14.9062401,16.0519481 C14.9062401,15.7263225 14.9299968,15.4000634 15.0256573,15.1675641 C15.2876148,14.5159962 15.8840672,13.8416218 16.8856509,13.8416218 C18.1970225,13.8416218 18.7218879,14.8416218 18.7218879,16.3078872 L18.7218879,22.1415901 L22.3465315,22.1415901 L22.3465315,15.8885017 C22.3465315,12.5388027 20.5584416,10.9800443 18.1735825,10.9800443 C16.2182452,10.9800443 15.3595185,12.072854 14.8824834,12.8172315 L14.9065569,12.8172315 L14.9065569,11.2359835 L11.2819132,11.2359835 C11.3291099,12.2591067 11.2815965,22.1419069 11.2815965,22.1419069 L11.2815965,22.1415901 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    
    
    
    <a class="social-icon" href="https://github.com/miguelbiron" target="_blank" rel="noopener" title="GitHub">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M13.9988029,1.32087331 C6.82105037,1.32087331 1,7.14112562 1,14.3212723 C1,20.0649109 4.72454649,24.9370678 9.89038951,26.6560892 C10.5408085,26.7757983 10.7778323,26.374374 10.7778323,26.0296121 C10.7778323,25.7215609 10.7666595,24.9035493 10.760275,23.8189856 C7.14426471,24.6042767 6.38131925,22.0760223 6.38131925,22.0760223 C5.78995672,20.5740732 4.93762853,20.1742451 4.93762853,20.1742451 C3.75729765,19.3682044 5.02701126,19.3841656 5.02701126,19.3841656 C6.33183953,19.4759425 7.01817121,20.7241085 7.01817121,20.7241085 C8.17775254,22.7104801 10.0611744,22.1366749 10.8017741,21.8038838 C10.919887,20.9643246 11.2558703,20.3913175 11.6269683,20.066507 C8.74038491,19.7385043 5.70536235,18.6228163 5.70536235,13.6413251 C5.70536235,12.2223743 6.21213051,11.0611968 7.04370914,10.1530044 C6.90963504,9.82420367 6.46351945,8.50181809 7.17139875,6.71256734 C7.17139875,6.71256734 8.26234691,6.36301702 10.7459099,8.04532771 C11.78259,7.75642995 12.8950858,7.61277914 14.000399,7.60719272 C15.1049142,7.61277914 16.2166119,7.75642995 17.2548881,8.04532771 C19.736855,6.36301702 20.8262071,6.71256734 20.8262071,6.71256734 C21.5356825,8.50181809 21.0895669,9.82420367 20.9562909,10.1530044 C21.7894656,11.0611968 22.2922435,12.2223743 22.2922435,13.6413251 C22.2922435,18.6355852 19.2524325,19.734514 16.3570705,20.0561322 C16.8231376,20.4575564 17.2389269,21.2508282 17.2389269,22.4638795 C17.2389269,24.2012564 17.2229657,25.603448 17.2229657,26.0296121 C17.2229657,26.3775663 17.4575954,26.7821827 18.116793,26.6552912 C23.2786458,24.9322794 27,20.0633148 27,14.3212723 C27,7.14112562 21.1789496,1.32087331 13.9988029,1.32087331"></path>
        </svg>
    </a>
    

    
    <a class="social-icon" href="https://stackoverflow.com/users/5443023" target="_blank" rel="noopener" title="Stack Overflow">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M20.8863636,23.7090909 L20.8863636,17.3818182 L22.9863636,17.3818182 L22.9863636,25.8090909 L4.03181818,25.8090909 L4.03181818,17.3818182 L6.13181818,17.3818182 L6.13181818,23.7090909 L20.8863636,23.7090909 Z M8.45,16.7818182 L8.88636364,14.7090909 L19.1954545,16.8636364 L18.7590909,18.9363636 L8.45,16.7818182 Z M9.81363636,11.8727273 L10.6863636,9.93636364 L20.2318182,14.4090909 L19.3590909,16.3181818 L9.81363636,11.8727273 Z M12.4590909,7.18181818 L13.7954545,5.57272727 L21.8954545,12.3090909 L20.5590909,13.9181818 L12.4590909,7.18181818 Z M17.6954545,2.19090909 L23.9681818,10.6454545 L22.2772727,11.9 L16.0045455,3.44545455 L17.6954545,2.19090909 Z M8.23181818,21.5818182 L8.23181818,19.4818182 L18.7590909,19.4818182 L18.7590909,21.5818182 L8.23181818,21.5818182 Z"></path>
        </svg>
    </a>
    
    
    

    
</div>




	<p><a href="https://github.com/kimcc/hugo-theme-noteworthy" target="_blank" rel="noopener">Noteworthy theme</a></p>
	<p><a href="https://gohugo.io" target="_blank" rel="noopener">Built with Hugo</a></p>

	<script src="/js/main.min.a7205ef73b078c8daed6fe1b0826e8ba229ffabbb69d299d9446cf41f2c7d8aa.js" integrity="sha256-pyBe9zsHjI2u1v4bCCbouiKf+ru2nSmdlEbPQfLH2Ko="></script>
</footer>
</nav>

        <div id="content" class="content-container">
        
<h1 class="post-title">PhD Qualifying Course Reports: Term 1</h1>
    
    <time>December 9, 2018</time>
    
    <div>
        <p>
        


<p>It’s crazy how fast this first term went by! But I loved it. The Department of Statistics at UBC is insanely awesome. The people are the best, from students to faculty and staff. The academic environment is very stimulating, especially in my area of interest, with lots of active reading groups and frequent seminars related to Bayesian Statistics, Probabilistic Models and Statistical Learning. We even had the privilege of attending a talk by the expert in Hamiltonian Monte Carlo <a href="https://betanalpha.github.io/">Michael Betancourt</a>. We also have lots of interaction with people from <a href="https://www.cs.ubc.ca/~fwood/">Frank Wood</a>’s group at the CS department. And finally, the UBC Vancouver campus is so beautiful! Definitely worth a visit if you happen to be in the city (which also deserves to be visited in itself!).</p>
<p>In this post I wanted to give an overview of the work I did for the <a href="https://www.stat.ubc.ca/phd-qualifying-course">Qualifying Course</a> (STAT548) in this first term. The idea of this course is that the student works on 5 papers with 5 different faculty, between term 1 and 2. Every professor posts a list of the papers he or she is interested in and the students choose among them or can also propose one too.</p>
<p>For each paper, the student has to write a report that shows, first, a thorough description of the method, including complete proofs of results whose derivations are usually only partially shown in the original manuscripts. Secondly, one has to implement the method in R or other programming language. Thirdly, the student must evaluate the method on both simulated and real datasets. Finally, one is to give a critique of the method based on the findings of the previous sections, suggesting avenues of improvement.</p>
<div id="paper-1-black-box-variational-inference" class="section level2">
<h2>Paper 1: Black box variational inference</h2>
<p><a href="/docs/STAT548_report_1_BBVI.pdf"><em>Download report 1.</em></a></p>
<p>In my first report, I worked with <a href="https://trevorcampbell.me/">Prof. Trevor Campbell</a>, who had just arrived to UBC after finishing his post-doc with <a href="http://www.tamarabroderick.com/">Prof. Tamara Broderick</a> at MIT. Interesting fact: before arriving to UBC, I didn’t know that Trevor had joined the department, but I knew about his research because Prof. Broderick gave a talk in Chile at the <a href="http://www.mat.uc.cl/noticias/2017-10-05/tamara-broderick-dictara-minicurso-en-nuestra-facultad.html">Statistics Department at PUC in 2017</a> (Spanish). She gave an excellent introduction to the topic of nonparametric Bayes, focusing on the case of the Dirichlet process for mixture models. It was an amazing talk overall. After that, I googled her and found about Trevor’s research, which can be grossly oversimplified as focusing on scalable Bayesian inference with theoretical guarantees. I found this very interesting, so it was exciting to find out he had moved to UBC during the summer. In fact, I joined his reading group right away and had the honor of giving the first talk, which was also about this work.</p>
<p>Back to the paper. After a very motivating talk with Trevor, I decided to work on the paper “Black-box Variational Inference” (BBVI) <span class="citation">(Ranganath, Gerrish, and Blei 2014)</span>. I chose it because I had used ADVI in Stan before, which I found to be very useful, and BBVI was a previous, slightly different attempt by <a href="http://www.cs.columbia.edu/~blei/">David Blei’s group</a> at tackling the problem of automatic variational inference (VI). The rest of the papers also sounded very interesting, but more mathematically intensive. Given that nor my undergrad nor my masters degree was in math, I have some gaps in Analysis and Measure Theory that I will be trying to fill during my stay here at UBC (for example, this term I attended the lectures of MATH 320 Real Variables I given by <a href="https://www.math.ubc.ca/~jzahl/">Joshua Zahl</a>, which were amazing, and I plan to do the same with MATH 321).</p>
<p>I won’t go into the details of the report. The main findings can be summarized as:</p>
<ol style="list-style-type: decimal">
<li>It is <strong>very difficult</strong> to actually get BBVI to yield meaningful results, even after using all the improvements proposed by the authors, like Rao-Blackwellization and Control Variates for reducing the variance of the estimator of the gradient of the ELBO (I actually discovered these variance-reducing techniques because of this paper), and AdaGrad for adaptively setting the learning rate.</li>
<li>One practical reason for the above is that the algorithm doesn’t deal well with bounded variational parameters. Hence, you have to manually define hard-thresholds for the updates. This leads to a trade-off: on the one hand, the gradients explode at the theoretical boundary, so you want to be far from it. On the other hand, the optimal value may lie arbitrarily close to that boundary, so you don’t want to impose a threshold that is too far away. Striking the balance for all models and datasets is not trivial!</li>
<li>Even for unbounded parameters, the magnitudes of the gradients become very large when the current parameter lies too far away from the optimum. It is therefore useful to set reasonable bounds for all parameters, which faces the same trade-off described above.</li>
<li>Even though it doesn’t fully solve the above problems, AdaGrad becomes extremely useful, as it dramatically reduces the step size when facing exploding gradients. However, one therefore needs to also tune its parameter, which can greatly affect the speed at which BBVI converges.</li>
</ol>
<p>I suggested some trivial improvements, which I later found out were already implemented in ADVI. However, it is important to note a crucial distinction between ADVI and BBVI: the former uses the so called “reparameterization gradient trick”, which I won’t describe here but has the implication that the posterior density needs to be differentiable with respect to the latent variables. Thus, no discrete latent variables allowed! In contrast, BBVI uses the “REINFORCE” trick, which only requires the ELBO to be differentiable with respect to the variational parameters, so discrete latent variables can be used. Hence, it would still be meaningful to ask for an implementation of BBVI in a probabilistic programming language like Stan, because it can accommodate a broader class of models than ADVI.</p>
<p>Now that I think about, it is possible that using natural gradients would yield an improvement. I would to check if they could be implemented in a “black box” way, such that the adjustment only depended on the variational family used.</p>
</div>
<div id="paper-2-the-elastic-net" class="section level2">
<h2>Paper 2: The elastic net</h2>
<p><a href="/docs/STAT548_report_2_Elasticnet.pdf"><em>Download report 2.</em></a></p>
<p>In my second paper I had to switch to the dark (i.e. frequentist) side of the stats. Although, I have to say I was very lucky to be able to work with <a href="https://gcohenfr.github.io/">Prof. Gabriela Cohen</a>. She is one of the Canada Research Chair (CRC) Tier 2 that our department is proud to have, so her curriculum was already impressive. Like me, she also comes from the south, but she’s from our neighbor country Argentina. So one day, probably the first week of class, I showed up at her office and she invited me in and we talked for hours about how was for her coming here to work and live with her family. I though it was really nice of her to just lend me her time for a conversation like this, and thus I immediately thought about working with her for the second paper.</p>
<p>So I emailed her right after finishing my first paper and she was happy to advise me. We agreed that I was gonna work on the classic Elastic Net paper by <span class="citation">Zou and Hastie (2005)</span>. I was thrilled, because I had used this model and the Lasso countless times while working at SBIF back in Chile, but never had the time to actually go over the theory.</p>
<p>The way of working with Gabriela was very different than with Trevor. She actually gave me a very specific list of questions I had to answer, as opposed to the more open-ended way in which the first report went. In any case, having a list of questions reduces anxiety in relation to what is expected from the one’s work, so I was fine with it.</p>
<p>In my opinion, the most fun I had with it was giving a proof of the fact that, in the <code>$p&gt;n$</code> situation (i.e., more covariates than observations), the Lasso can select at most <code>$n$</code> covariates, while showing that the Elastic Net does not suffer from this issue. It was interesting because it forced me to learn about KKT conditions for subgradients (I have never taken a course on convex optimization), while at the same time refreshing my linear algebra. I also remember being greatly surprised when I found out that orthonormal design matrices had analytic solutions for the Elastic Net. So, even though this was not part of the questions, I gave a proof of the solution, which is in fact univariate soft-thresholding.</p>
<p>On the other hand, I’d say that the most difficult part of this report was finding a way to give a meaningful critique to a 13 years old, seminal work. Nevertheless, as a Bayesian, the most troubling aspect of this paper is that it does not give any advice on how to obtain uncertainty measures of the estimated parameters, so that the user is forced to use a bootstrap strategy. This can be prohibitive for large datasets, since for each bootstrap run, one has to perform cross-validation to find the optimal parameters. In contrast, the “spike-and-slab” prior, the gold standard of Bayesian variable selection which dates back to <span class="citation">Mitchell and Beauchamp (1988)</span>, can yield exact post selection inference effortlessly.</p>
<p>In fact, after handing in the report, I went and implemented a spike-and-slab model for a linear regression. I used the more modern implementation, which uses an auxiliary binary vector <code>$z$</code> with entries in <code>$\{0, 1\}$</code>, so that the model becomes:
<span class="math display">\[
\begin{aligned}
\sigma_b^2 &amp;\sim \text{Inv-Gamma}(e, f) \\
\sigma_e^2 &amp;\sim \text{Inv-Gamma}(g, h) \\
\beta|\sigma_b^2 &amp;\sim \mathcal{N}(0_p, \sigma_b^2 I_p) \\
\pi_k &amp;\overset{iid}{\sim} \text{Beta}(a,b) \\
z_k|\pi_k &amp;\overset{ind}{\sim} \text{Bernoulli}(\pi_k) \\
y_i|z, \beta, \sigma_e &amp;\overset{ind}{\sim} \mathcal{N}(x_i^T(\beta \odot z), \sigma_e^2)
\end{aligned}
\]</span></p>
<p>where <code>$\odot$</code> is the Hadamard or element-wise product. Because of the conjugacies present, a Gibbs sampler is straightforward to derive. In this setup, <code>$\tilde{\beta} \triangleq \beta \odot z$</code> becomes the object of post-selection inference. In terms of performance and number of variables selected, I obtained very similar results to the ones that Elastic Net produces, which was satisfactory. I may upload this implementation to a Github repository with an accompanying blog post when I have time, since I couldn’t find an R implementation for it. However, in the next paper you can see how Beta-Bernoulli processes, the limit for the Beta-Bernoulli conjugate variables used above, can be used to construct infinite sparse binary matrices.</p>
</div>
<div id="paper-3-nonparametric-bayesian-sparse-factor-models" class="section level2">
<h2>Paper 3: Nonparametric Bayesian sparse factor models</h2>
<p><a href="/docs/STAT548_report_3_NSFA.pdf"><em>Download report 3.</em></a></p>
<p>The fact that I chose not to be a TA this term, and also that I had only one course, let me focus 80% of my time to the Qualifying Course. Becasue of this, I was able to get 3 papers done in the first term, something that was surprising, according to the graduate advisor and staff.</p>
<p>Luckily, after finishing my second report, Prof. Alex Bouchard-Côté had just returned from a sabbatical. I have to say that Alex was a crucial factor in my decision to come to UBC, because he was one of the few Bayesians here, his curriculum is impressive, and his research on MCMC methods is very motivating. So I went to talk to him and offered to work on the paper by <span class="citation">Knowles and Ghahramani (2011)</span>, which he accepted. I also took the liberty of asking him permission to join his reading group, and he was very welcoming about it. I have thoroughly enjoyed every meeting (in fact, I will be presenting next week about perfect sampling).</p>
<p>Back to paper. This work proposes the Nonparametric Sparse Factor Analysis (NSFA) model. Recall the standard construction of Factor Analysis:
<span class="math display">\[
Y = GX + E
\]</span></p>
<p>where <code>$Y$</code> is the data (a <code>$D \times N$</code> matrix), <code>$X$</code> is matrix of size <code>$K \times N$</code> containing <code>$K$</code> latent factors, <code>$G$</code> is the loading matrix of the <code>$D$</code> objects onto the <code>$K$</code> factors. In short, the NSFA uses an Indian Buffet Process (IBP) in the prior of <code>$G$</code> to allow for an unbounded number of latent factors, while at the same time imposing sparsity on the weights.</p>
<p>This report was definitely the one in which I spent more time. I had to quickly learn about the IBP (my only exposure to nonparametric Bayes had been the lecture by Prof. Broderick I mentioned above), as it was a key aspect of the paper. Thus, I spent a lof of time deriving its properties, some of which are missing from the papers in which it is presented. So if you are also looking for those derivations, take a look at the report! Although, there was one particular equation that I could never derive. I even made <a href="https://math.stackexchange.com/q/2986123/612568">a question in stackexchange</a> about it which still hasn’t been asnwered and that earned me the “tumbleweed badge”!.</p>
<p>After spending 10 pages solely on the IBP, I went on to describing the NSFA. It took me another 13 pages to derive all the Gibbs updates! It was actually very hard, because most of them were simply stated in the original paper. Also, it contained many typos, so I spent a lot of time simply making sure that my derivations were correct. The worst part was deriving the most complex update, which relates to growing the active set of latent factors. Here I found errors in the derivation of the acceptance ratio of a Metropolis-Hastings-within-Gibbs step used. Because I couldn’t believe that this published paper had an error on it, I freaked out, and basically derived everything from scratch many times, until I convinced myself that my result was the correct one.</p>
<p>From this, I concluded that there was a clear lesson for my future as an academic: the attitude towards every paper should be one of close scrutiny, of doubting everything, as cliche as it may sound. Review processes are less than ideal, even in the most respected journals. That is why like so much both Trevor’s and Alex’s reading groups, because we go over every detail (of at least the main results) of the papers we select. In the end, this critical approach is benefitial for everyone.</p>
<p>Besides the typos and errors in the derivations that I found, my main critique towards the paper was that it performed very poorly in terms of out-of-sample evaluation. I applied it to a subset of the MNIST dataset, basically because I had always wanted an excuse to analyze that famous dataset. The NSFA fitted the training set very well (check out the pictures in the report!), but the predictive log-likelihood in the test set only decreased as iterations went by. I gave reasons for this behavior, emphasizing the need to give more structure to the model.</p>
</div>
<div id="final-remarks" class="section level2">
<h2>Final remarks</h2>
<p>Overall, I have to say that this term exceeded any expectations I had about my first year as a PhD student. I absolutely loved it, in spite of all the work it involved. I just hope that the following terms be as fun as this was for me. Happy holidays!</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-knowles2011nonparametric">
<p>Knowles, David, and Zoubin Ghahramani. 2011. “Nonparametric Bayesian Sparse Factor Models with Application to Gene Expression Modeling.” <em>The Annals of Applied Statistics</em>. JSTOR, 1534–52.</p>
</div>
<div id="ref-mitchell1988bayesian">
<p>Mitchell, Toby J, and John J Beauchamp. 1988. “Bayesian Variable Selection in Linear Regression.” <em>Journal of the American Statistical Association</em> 83 (404). Taylor &amp; Francis Group: 1023–32.</p>
</div>
<div id="ref-ranganath2014">
<p>Ranganath, Rajesh, Sean Gerrish, and David Blei. 2014. “Black Box Variational Inference.” In <em>Artificial Intelligence and Statistics</em>, 814–22.</p>
</div>
<div id="ref-zou2005regularization">
<p>Zou, Hui, and Trevor Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 67 (2). Wiley Online Library: 301–20.</p>
</div>
</div>
</div>

        </p>
    </div>
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "the-mblog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    <div class="page-footer">
        <hr class="footer-divider">
        
        
            <a class="tag" href="/tags/qualifying-course">#qualifying course</a>
        
            <a class="tag" href="/tags/bbvi">#bbvi</a>
        
            <a class="tag" href="/tags/elasticnet">#elasticnet</a>
        
            <a class="tag" href="/tags/nonparametric-bayes">#nonparametric bayes</a>
        
            <a class="tag" href="/tags/factor-analysis">#factor analysis</a>
        
      
    </div>


        

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>


<script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>



<script src="/js/math-code.js"></script>


<script>
      renderMathInElement(
          document.body,
          {
              delimiters: [
                  {left: "$$", right: "$$", display: true},
                  {left: "\\[", right: "\\]", display: true},
                  {left: "$", right: "$", display: false},
                  {left: "\\(", right: "\\)", display: false}
              ]
          }
      );
</script>

        </div>
        <footer class="footer-mobile">
	<div class="social-icons">
        
    <a class="social-icon" href="mailto:miguel.biron@stat.ubc.ca" target="_blank" rel="noopener" title="Email">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M25.2794292,5.59128519 L14,16.8707144 L2.72057081,5.59128519 C3.06733103,5.30237414 3.51336915,5.12857603 4,5.12857603 L24,5.12857603 C24.4866308,5.12857603 24.932669,5.30237414 25.2794292,5.59128519 Z M25.9956978,6.99633695 C25.998551,7.04004843 26,7.08414302 26,7.12857603 L26,20.871424 C26,21.0798433 25.9681197,21.2808166 25.9089697,21.4697335 L18.7156355,14.2763993 L25.9956978,6.99633695 Z M24.9498374,22.6319215 C24.6672737,22.7846939 24.3437653,22.871424 24,22.871424 L4,22.871424 C3.5268522,22.871424 3.09207889,22.7071233 2.74962118,22.432463 L10.0950247,15.0870594 L13.9848068,18.9768415 L14.1878486,18.7737996 L14.2030419,18.7889929 L17.6549753,15.3370594 L24.9498374,22.6319215 Z M2.00810114,21.0526627 C2.00273908,20.9929669 2,20.9325153 2,20.871424 L2,7.12857603 C2,7.08414302 2.00144896,7.04004843 2.00430222,6.99633695 L9.03436454,14.0263993 L2.00810114,21.0526627 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    

    

    

    
    <a class="social-icon" href="https://linkedin.com/in/miguelbiron" target="_blank" rel="noopener" title="LinkedIn">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M2,3.654102 C2,2.69908141 2.79442509,1.92397846 3.77383592,1.92397846 L24.2261641,1.92397846 C25.2058917,1.92397846 26,2.69908141 26,3.654102 L26,24.3462148 C26,25.3015521 25.2058917,26.0760215 24.2261641,26.0760215 L3.77383592,26.0760215 C2.79442509,26.0760215 2,25.3015521 2,24.3465315 L2,3.65378524 L2,3.654102 Z M9.27526132,22.1415901 L9.27526132,11.2356668 L5.65030092,11.2356668 L5.65030092,22.1415901 L9.27557808,22.1415901 L9.27526132,22.1415901 Z M7.46341463,9.74691162 C8.72727273,9.74691162 9.51409566,8.90940767 9.51409566,7.86284447 C9.49033893,6.79252455 8.72727273,5.97846056 7.48748812,5.97846056 C6.24675325,5.97846056 5.43649034,6.79252455 5.43649034,7.86284447 C5.43649034,8.90940767 6.22299652,9.74691162 7.4396579,9.74691162 L7.46309788,9.74691162 L7.46341463,9.74691162 Z M11.2815965,22.1415901 L14.9062401,22.1415901 L14.9062401,16.0519481 C14.9062401,15.7263225 14.9299968,15.4000634 15.0256573,15.1675641 C15.2876148,14.5159962 15.8840672,13.8416218 16.8856509,13.8416218 C18.1970225,13.8416218 18.7218879,14.8416218 18.7218879,16.3078872 L18.7218879,22.1415901 L22.3465315,22.1415901 L22.3465315,15.8885017 C22.3465315,12.5388027 20.5584416,10.9800443 18.1735825,10.9800443 C16.2182452,10.9800443 15.3595185,12.072854 14.8824834,12.8172315 L14.9065569,12.8172315 L14.9065569,11.2359835 L11.2819132,11.2359835 C11.3291099,12.2591067 11.2815965,22.1419069 11.2815965,22.1419069 L11.2815965,22.1415901 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    
    
    
    <a class="social-icon" href="https://github.com/miguelbiron" target="_blank" rel="noopener" title="GitHub">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M13.9988029,1.32087331 C6.82105037,1.32087331 1,7.14112562 1,14.3212723 C1,20.0649109 4.72454649,24.9370678 9.89038951,26.6560892 C10.5408085,26.7757983 10.7778323,26.374374 10.7778323,26.0296121 C10.7778323,25.7215609 10.7666595,24.9035493 10.760275,23.8189856 C7.14426471,24.6042767 6.38131925,22.0760223 6.38131925,22.0760223 C5.78995672,20.5740732 4.93762853,20.1742451 4.93762853,20.1742451 C3.75729765,19.3682044 5.02701126,19.3841656 5.02701126,19.3841656 C6.33183953,19.4759425 7.01817121,20.7241085 7.01817121,20.7241085 C8.17775254,22.7104801 10.0611744,22.1366749 10.8017741,21.8038838 C10.919887,20.9643246 11.2558703,20.3913175 11.6269683,20.066507 C8.74038491,19.7385043 5.70536235,18.6228163 5.70536235,13.6413251 C5.70536235,12.2223743 6.21213051,11.0611968 7.04370914,10.1530044 C6.90963504,9.82420367 6.46351945,8.50181809 7.17139875,6.71256734 C7.17139875,6.71256734 8.26234691,6.36301702 10.7459099,8.04532771 C11.78259,7.75642995 12.8950858,7.61277914 14.000399,7.60719272 C15.1049142,7.61277914 16.2166119,7.75642995 17.2548881,8.04532771 C19.736855,6.36301702 20.8262071,6.71256734 20.8262071,6.71256734 C21.5356825,8.50181809 21.0895669,9.82420367 20.9562909,10.1530044 C21.7894656,11.0611968 22.2922435,12.2223743 22.2922435,13.6413251 C22.2922435,18.6355852 19.2524325,19.734514 16.3570705,20.0561322 C16.8231376,20.4575564 17.2389269,21.2508282 17.2389269,22.4638795 C17.2389269,24.2012564 17.2229657,25.603448 17.2229657,26.0296121 C17.2229657,26.3775663 17.4575954,26.7821827 18.116793,26.6552912 C23.2786458,24.9322794 27,20.0633148 27,14.3212723 C27,7.14112562 21.1789496,1.32087331 13.9988029,1.32087331"></path>
        </svg>
    </a>
    

    
    <a class="social-icon" href="https://stackoverflow.com/users/5443023" target="_blank" rel="noopener" title="Stack Overflow">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M20.8863636,23.7090909 L20.8863636,17.3818182 L22.9863636,17.3818182 L22.9863636,25.8090909 L4.03181818,25.8090909 L4.03181818,17.3818182 L6.13181818,17.3818182 L6.13181818,23.7090909 L20.8863636,23.7090909 Z M8.45,16.7818182 L8.88636364,14.7090909 L19.1954545,16.8636364 L18.7590909,18.9363636 L8.45,16.7818182 Z M9.81363636,11.8727273 L10.6863636,9.93636364 L20.2318182,14.4090909 L19.3590909,16.3181818 L9.81363636,11.8727273 Z M12.4590909,7.18181818 L13.7954545,5.57272727 L21.8954545,12.3090909 L20.5590909,13.9181818 L12.4590909,7.18181818 Z M17.6954545,2.19090909 L23.9681818,10.6454545 L22.2772727,11.9 L16.0045455,3.44545455 L17.6954545,2.19090909 Z M8.23181818,21.5818182 L8.23181818,19.4818182 L18.7590909,19.4818182 L18.7590909,21.5818182 L8.23181818,21.5818182 Z"></path>
        </svg>
    </a>
    
    
    

    
</div>




	<div class="footer-mobile-links">
		<p><a href="https://github.com/kimcc/hugo-theme-noteworthy" target="_blank" rel="noopener">Noteworthy theme</a></p>
		<span class="divider-bar">|</span>
		<p><a href="https://gohugo.io" target="_blank" rel="noopener">Built with Hugo</a></p>
	</div>

	<script src="/js/main.min.a7205ef73b078c8daed6fe1b0826e8ba229ffabbb69d299d9446cf41f2c7d8aa.js" integrity="sha256-pyBe9zsHjI2u1v4bCCbouiKf+ru2nSmdlEbPQfLH2Ko="></script>
</footer>
    </body>
</html>