<!DOCTYPE html>

<html lang="en-us">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="format-detection" content="telephone=no"/>

    <title>Miguel Biron-Lattes</title>
    
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/manifest.json">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#FF3DB4">
    <meta name="theme-color" content="#ffffff">

    
    
    
    <link rel="stylesheet" href="/css/main.min.03322cbe6bddfc28e7b17b84bc5446282a510b14b57be3371ba1f68ef1ab9ce8.css"/>
    
    
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/xcode.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

    
    
    

    
    <link type="text/css" rel="stylesheet" href="/css/custom.css">
 
    
    
</head>
    <body>
        
<nav>
  <header>
    <div class="site-title">
        <a href="/">Miguel Biron-Lattes</a>
    </div>  
</header>
  <div class="nav-menu">
  
    <a class="color-link nav-link" href="/post/">Blog</a>
  
    <a class="color-link nav-link" href="/tags/">Tags</a>
  
    <a class="color-link nav-link" href="/archives/">Archives</a>
  
  <a class="color-link nav-link" href="/index.xml" target="_blank" rel="noopener" type="application/rss+xml">RSS</a>
</div>
<footer class="footer">
	<div class="social-icons">
        
    <a class="social-icon" href="mailto:miguel.biron@stat.ubc.ca" target="_blank" rel="noopener" title="Email">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M25.2794292,5.59128519 L14,16.8707144 L2.72057081,5.59128519 C3.06733103,5.30237414 3.51336915,5.12857603 4,5.12857603 L24,5.12857603 C24.4866308,5.12857603 24.932669,5.30237414 25.2794292,5.59128519 Z M25.9956978,6.99633695 C25.998551,7.04004843 26,7.08414302 26,7.12857603 L26,20.871424 C26,21.0798433 25.9681197,21.2808166 25.9089697,21.4697335 L18.7156355,14.2763993 L25.9956978,6.99633695 Z M24.9498374,22.6319215 C24.6672737,22.7846939 24.3437653,22.871424 24,22.871424 L4,22.871424 C3.5268522,22.871424 3.09207889,22.7071233 2.74962118,22.432463 L10.0950247,15.0870594 L13.9848068,18.9768415 L14.1878486,18.7737996 L14.2030419,18.7889929 L17.6549753,15.3370594 L24.9498374,22.6319215 Z M2.00810114,21.0526627 C2.00273908,20.9929669 2,20.9325153 2,20.871424 L2,7.12857603 C2,7.08414302 2.00144896,7.04004843 2.00430222,6.99633695 L9.03436454,14.0263993 L2.00810114,21.0526627 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    

    

    

    
    <a class="social-icon" href="https://linkedin.com/in/miguelbiron" target="_blank" rel="noopener" title="LinkedIn">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M2,3.654102 C2,2.69908141 2.79442509,1.92397846 3.77383592,1.92397846 L24.2261641,1.92397846 C25.2058917,1.92397846 26,2.69908141 26,3.654102 L26,24.3462148 C26,25.3015521 25.2058917,26.0760215 24.2261641,26.0760215 L3.77383592,26.0760215 C2.79442509,26.0760215 2,25.3015521 2,24.3465315 L2,3.65378524 L2,3.654102 Z M9.27526132,22.1415901 L9.27526132,11.2356668 L5.65030092,11.2356668 L5.65030092,22.1415901 L9.27557808,22.1415901 L9.27526132,22.1415901 Z M7.46341463,9.74691162 C8.72727273,9.74691162 9.51409566,8.90940767 9.51409566,7.86284447 C9.49033893,6.79252455 8.72727273,5.97846056 7.48748812,5.97846056 C6.24675325,5.97846056 5.43649034,6.79252455 5.43649034,7.86284447 C5.43649034,8.90940767 6.22299652,9.74691162 7.4396579,9.74691162 L7.46309788,9.74691162 L7.46341463,9.74691162 Z M11.2815965,22.1415901 L14.9062401,22.1415901 L14.9062401,16.0519481 C14.9062401,15.7263225 14.9299968,15.4000634 15.0256573,15.1675641 C15.2876148,14.5159962 15.8840672,13.8416218 16.8856509,13.8416218 C18.1970225,13.8416218 18.7218879,14.8416218 18.7218879,16.3078872 L18.7218879,22.1415901 L22.3465315,22.1415901 L22.3465315,15.8885017 C22.3465315,12.5388027 20.5584416,10.9800443 18.1735825,10.9800443 C16.2182452,10.9800443 15.3595185,12.072854 14.8824834,12.8172315 L14.9065569,12.8172315 L14.9065569,11.2359835 L11.2819132,11.2359835 C11.3291099,12.2591067 11.2815965,22.1419069 11.2815965,22.1419069 L11.2815965,22.1415901 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    
    
    
    <a class="social-icon" href="https://github.com/miguelbiron" target="_blank" rel="noopener" title="GitHub">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M13.9988029,1.32087331 C6.82105037,1.32087331 1,7.14112562 1,14.3212723 C1,20.0649109 4.72454649,24.9370678 9.89038951,26.6560892 C10.5408085,26.7757983 10.7778323,26.374374 10.7778323,26.0296121 C10.7778323,25.7215609 10.7666595,24.9035493 10.760275,23.8189856 C7.14426471,24.6042767 6.38131925,22.0760223 6.38131925,22.0760223 C5.78995672,20.5740732 4.93762853,20.1742451 4.93762853,20.1742451 C3.75729765,19.3682044 5.02701126,19.3841656 5.02701126,19.3841656 C6.33183953,19.4759425 7.01817121,20.7241085 7.01817121,20.7241085 C8.17775254,22.7104801 10.0611744,22.1366749 10.8017741,21.8038838 C10.919887,20.9643246 11.2558703,20.3913175 11.6269683,20.066507 C8.74038491,19.7385043 5.70536235,18.6228163 5.70536235,13.6413251 C5.70536235,12.2223743 6.21213051,11.0611968 7.04370914,10.1530044 C6.90963504,9.82420367 6.46351945,8.50181809 7.17139875,6.71256734 C7.17139875,6.71256734 8.26234691,6.36301702 10.7459099,8.04532771 C11.78259,7.75642995 12.8950858,7.61277914 14.000399,7.60719272 C15.1049142,7.61277914 16.2166119,7.75642995 17.2548881,8.04532771 C19.736855,6.36301702 20.8262071,6.71256734 20.8262071,6.71256734 C21.5356825,8.50181809 21.0895669,9.82420367 20.9562909,10.1530044 C21.7894656,11.0611968 22.2922435,12.2223743 22.2922435,13.6413251 C22.2922435,18.6355852 19.2524325,19.734514 16.3570705,20.0561322 C16.8231376,20.4575564 17.2389269,21.2508282 17.2389269,22.4638795 C17.2389269,24.2012564 17.2229657,25.603448 17.2229657,26.0296121 C17.2229657,26.3775663 17.4575954,26.7821827 18.116793,26.6552912 C23.2786458,24.9322794 27,20.0633148 27,14.3212723 C27,7.14112562 21.1789496,1.32087331 13.9988029,1.32087331"></path>
        </svg>
    </a>
    

    
    <a class="social-icon" href="https://stackoverflow.com/users/5443023" target="_blank" rel="noopener" title="Stack Overflow">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M20.8863636,23.7090909 L20.8863636,17.3818182 L22.9863636,17.3818182 L22.9863636,25.8090909 L4.03181818,25.8090909 L4.03181818,17.3818182 L6.13181818,17.3818182 L6.13181818,23.7090909 L20.8863636,23.7090909 Z M8.45,16.7818182 L8.88636364,14.7090909 L19.1954545,16.8636364 L18.7590909,18.9363636 L8.45,16.7818182 Z M9.81363636,11.8727273 L10.6863636,9.93636364 L20.2318182,14.4090909 L19.3590909,16.3181818 L9.81363636,11.8727273 Z M12.4590909,7.18181818 L13.7954545,5.57272727 L21.8954545,12.3090909 L20.5590909,13.9181818 L12.4590909,7.18181818 Z M17.6954545,2.19090909 L23.9681818,10.6454545 L22.2772727,11.9 L16.0045455,3.44545455 L17.6954545,2.19090909 Z M8.23181818,21.5818182 L8.23181818,19.4818182 L18.7590909,19.4818182 L18.7590909,21.5818182 L8.23181818,21.5818182 Z"></path>
        </svg>
    </a>
    
    
    

    
</div>




	<p><a href="https://github.com/kimcc/hugo-theme-noteworthy" target="_blank" rel="noopener">Noteworthy theme</a></p>
	<p><a href="https://gohugo.io" target="_blank" rel="noopener">Built with Hugo</a></p>

	<script src="/js/main.min.fa5c2b23e07b5d9bfad267a52b4b24fdb053e6fb7524993383594926a3ac270c.js" integrity="sha256-+lwrI+B7XZv60melK0sk/bBT5vt1JJkzg1lJJqOsJww="></script>
</footer>
</nav>
        <div id="content" class="content-container">
        
<h1 class="post-title">New member in SBGLM: sparse linear regression</h1>
    
    <time>January 6, 2019</time>
    
    <div>
        <p>
        


<p>Hi all!</p>
<p>This blog is about the latest addition to my <a href="https://github.com/miguelbiron/SBGLM">package SBGLM</a>: a sparse linear regression. This was actually the first model I intended to put in the package, but I didn’t had time to finish implementing it during last term.</p>
<div id="description-of-the-model" class="section level2">
<h2>Description of the model</h2>
<p>This is a very basic Bayesian linear regression model, with a minor twist that lets us impose sparsity in the effects: <code>$$ \begin{aligned} \sigma_b^2 &amp;\sim \text{Inv-Gamma}(s_b, r_b) \\ \sigma_e^2 &amp;\sim \text{Inv-Gamma}(s_e, r_e) \\ \pi &amp;\sim \text{Beta}(s_1, s_2) \\ \beta_k|\sigma_b^2 &amp;\overset{iid}{\sim} \mathcal{N}(0, \sigma_b^2) \\ z_k|\pi &amp;\overset{iid}{\sim} \text{Bernoulli}(\pi) \\ y|\beta, z, X, \sigma_e^2 &amp;\sim \mathcal{N}(X(\beta \odot z), \sigma_e^2 I_N) \end{aligned} $$</code></p>
<p>where <code>$\odot$</code> is the Hadamard (element-wise) product of two vectors, <code>$y$</code> is the vector of responses of length <code>$N$</code>, and <code>$X$</code> is a matrix of covariates of size <code>$N\times P$</code>. As you can see, the way sparsity is introduced is by “masking” or “switching on and off” components of <code>$\beta$</code> using the binary variables <code>$z$</code>. Thus, the effect of a given covariate <code>$x_k$</code> on the response will be <code>$\beta_k z_k$</code>, and not just <code>$\beta_k$</code>.</p>
<p>The oldest reference I know about this way of introducing sparsity in a Bayesian model is <span class="citation">Griffiths and Ghahramani (2011)</span>, although the technique might be older. I actually discovered it by myself, so I was glad when I saw that people had already been using it. Also, I’m almost sure that this is just an equivalent way of implementing the spike-and-slab prior, so that is why probably nobody mentions it as something new.</p>
<p>The posterior distribution is obtained by using a Gibbs sampler, which is easy to derive given the conjugacies present in the model. Everything is implemented using only base R, which I try to promote in order to minimize dependency issues in the future.</p>
<p>As with all things Bayesian, the beauty of this model resides in its assessment of uncertainty, since asymptotically (in MCMC runs) exact post-selection inference comes for free, something that for frequentist methods like Lasso <span class="citation">(Tibshirani 1996)</span> or the Elastic Net <span class="citation">(Zou and Hastie 2005)</span> has only very recently been made possible (see for example <span class="citation">Lee et al. (2016)</span>). Recall that the brute-force alternative for evaluation of post-selection uncertainty in such models was to bootstrap your dataset, having to do a full cross-validation search of parameters for each run. Needless to say, this quickly becomes unfeasible.</p>
<p>Indeed, the posterior distribution <code>$p(\beta \odot z|\mathcal{D})$</code> of the effects, where <code>$\mathcal{D} = \{y, X\}$</code>, contains all the relevant information for assessing uncertainty by explicitly accounting for the introduction of sparsity. In fact, the posterior <code>$p(z|\mathcal{D})$</code> of the switches themselves is also interesting, as it reveals the joint probability that each of the covariates is included in the model.</p>
</div>
<div id="gibbs-updates" class="section level2">
<h2>Gibbs updates</h2>
<p>In order to construct the Gibbs sampler, the first thing to notice is that, conditional on <code>$z$</code>, the model actually reduces to a standard Bayesian linear regression, where the design matrix is now <code>$X_{:A}$</code>, with <code>$A=\{k: z_k=1\}$</code> being the active set of covariates. Thus, the Gibbs updates in the sparse model for the active coefficients and the variances are exactly the same as for the standard model.</p>
<p>Recall that the update for <code>$\beta$</code> in a standard linear regression requires a matrix inversion. Here, we also face that problem. However, because we only do this for the active components, then as long as <code>$|A|$</code> is small (~100) this implementation runs in surprisingly reasonable times, regardless of how large <code>$P$</code> can be. In the future, I would like to test if having element-wise updates could be used to tackle larger problems, at the expense of perhaps having slower mixing times.</p>
<p>The inactive components <code>$\beta_{-A}$</code> still have to updated, though. It is easy to show that the full conditional is equal to the prior. This is very intuitive, because they are being disconnected from the model by their switches, so there is no information from the data that can be used to update our belief about them.</p>
<p>The update for the switches is the only one that is trickier to derive, so I leave it here for future reference: <code>$$ \frac{\mathbb{P}(z_k=1|-, \mathcal{D})}{\mathbb{P}(z_k=0|-, \mathcal{D})} = \exp \left( \log \pi -\log(1-\pi) - \frac{\beta_k}{2\sigma_e^2} \left[ -2(X^Ty)_{k} + \beta_k (X^TX)_{kk} + 2(X^TX)_{:k}^T(\beta \odot z_0) \right] \right) $$</code></p>
<p>where <code>$z_0$</code> is equal to <code>$z$</code> but has a 0 at the <code>$k$</code>-th position. Note that the computations that are expensive (<code>$X^Ty, X^TX$</code>) have to be calculated once and stored so that they’re available for re-use.</p>
<p>Finally, the update for <code>$\pi$</code> follows from the standard Beta-Bernoulli conjugacy: <code>$$ \pi|z \sim \text{Beta}\left(s_1 + \sum_k z_k, s_2 + P - \sum_k z_k \right) $$</code></p>
</div>
<div id="example-simulated-data" class="section level2">
<h2>Example: simulated data</h2>
<p>My intention here is to show you how this model performs by applying it to a simulated dataset. The data generating process is actually a modified version of one of the simulations that <span class="citation">Zou and Hastie (2005)</span> used to evaluate the Elastic Net. Their approach had a minor mistake, which I pointed out <a href="/post/2018-12-08-qualifying-course-reports-term-1/">in my report about this paper</a>. However, the fundamental ideas are the same: to assess the behavior of the model under the situation <code>$N \ll P$</code>, where only a few of the available covariates are relevant, and also when those variables are clumped into groups with high within-group correlation and between-group independence. This is achieved by creating groups of covariates from slightly perturbed sine functions, with each group having a different frequency. This way, we ensure that the covariates are uncorrelated. The problem with the method in the Elastic Net paper was that it wrongly used groups of constant features, so that the within-group correlation was actually 0, not as intended. Finally, all the variables in the relevant groups are assigned the same coefficient, and the rest are assigned a beta equal to 0.</p>
<p>Hopefully, the following code is clear enough so that the ideas of the previous paragraph are evident:</p>
<pre class="r"><code>get_data = function(N, P, nz_P, n_groups, b_val, sigma_b, sigma_e){
  # define beta
  p = nz_P %/% n_groups
  beta = numeric(P)
  beta[seq_len(nz_P)] = b_val
  
  # define groups of highly correlated variables
  # the lowest sigma_b is, the highest the within-group correlation
  X = do.call(cbind,
              lapply(seq_len(n_groups),
                     function(u) {
                       matrix(rep(sin(u * (1:N)), p), ncol=p) +
                         matrix(rnorm(N*p, sd= sigma_b), nrow=N)
                     }))
  
  # append many noise covariates
  X = cbind(X, matrix(rnorm(N*(P-nz_P)), nrow = N))
  
  # get response
  y = as.vector(X %*% beta) + rnorm(N, sd = sigma_e)
  
  return(list(X=X, y=y))
}</code></pre>
<p>Now we sample the data. The following plot shows the correlation matrix for the first 150 of the total 500 covariates, which shows exactly the pattern that we would expect.</p>
<pre class="r"><code>set.seed(1313)

N = 200L # number of observations
P = 500L # total number of covariates
nz_P = 45L # number of covariates with nonzero coefficients
n_groups = 5L # number of groups of covariates (nz_P/n_groups within each)
b_val = 3 # value of the effect for nonzero coefficients
sigma_b = 0.1 # noise added to covariates in the same group
sigma_e = 5 # noise in the response

dta = get_data(N, P, nz_P, n_groups, b_val, sigma_b, sigma_e)

# visualize correlations
M = cor(dta$X[,seq_len(150L)])
M = t(apply(M, 2, rev))
op = par(mar = rep(0, 4))
image(M, axes=FALSE, asp = 1, useRaster = TRUE)</code></pre>
<p><img src="/post/2019-01-06-new-sblm-in-sbglm_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(op)</code></pre>
<p>Now we are ready to run the Gibbs sampler on this data:</p>
<pre class="r"><code>library(SBGLM)

S=2000L
results = sblm_gibbs(
  X       = dta$X,
  y       = dta$y,
  S       = S,
  verbose = 200L
)</code></pre>
<pre><code>## Chain initialized. Beginning iterations!
## 
## Iteration 200: |A| = 11, sigma_2_e = 28.42, sigma_2_b = 122.48
## Iteration 400: |A| = 14, sigma_2_e = 25.95, sigma_2_b = 65.07
## Iteration 600: |A| = 12, sigma_2_e = 28.80, sigma_2_b = 67.35
## Iteration 800: |A| = 10, sigma_2_e = 30.75, sigma_2_b = 250.25
## Iteration 1000: |A| = 10, sigma_2_e = 32.57, sigma_2_b = 182.99
## Iteration 1200: |A| = 12, sigma_2_e = 29.33, sigma_2_b = 203.41
## Iteration 1400: |A| = 9, sigma_2_e = 27.43, sigma_2_b = 215.18
## Iteration 1600: |A| = 11, sigma_2_e = 30.91, sigma_2_b = 81.36
## Iteration 1800: |A| = 12, sigma_2_e = 28.91, sigma_2_b = 220.84
## Iteration 2000: |A| = 11, sigma_2_e = 35.74, sigma_2_b = 194.41</code></pre>
<p>Great! Let us plot the traces for <code>$\pi$</code> and the variances to check that everything is running as it should:</p>
<pre class="r"><code>suppressPackageStartupMessages(library(dplyr))
library(tidyr)
library(ggplot2)

t(sapply(results, function(l){
  c(l$pi_z, l$sigma_2_e, l$sigma_2_b)
})) %&gt;%
  as.data.frame.matrix() %&gt;%
  setNames(c(&quot;Pi&quot;, &quot;sigma_2_e&quot;, &quot;sigma_2_b&quot;)) %&gt;%
  mutate(Iteration = seq_len(S)) %&gt;%
  gather(&quot;key&quot;, &quot;Value&quot;, select = -Iteration) %&gt;%
  ggplot(aes(x = Iteration, y = Value, color = &quot;1&quot;)) +
  geom_line(show.legend = FALSE) +
  scale_y_log10() +
  theme_bw() +
  facet_wrap(~key, scales = &quot;free_y&quot;, ncol = 1L)</code></pre>
<p><img src="/post/2019-01-06-new-sblm-in-sbglm_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For <code>$\pi$</code> and <code>$\sigma_e^2$</code> we see the nice “fuzzy caterpillar” pattern that should emerge, and in fact both of them settle very quickly close to their true values. For <code>$\sigma_b^2$</code>, however, we observe a more random-walk behavior. Since its update depends only on the active coefficients, we now plot some of them:</p>
<pre class="r"><code>t(sapply(results, function(l){l$beta[c(5L, 40L, 140L)]})) %&gt;%
  as.data.frame.matrix() %&gt;%
  setNames(paste(&quot;Beta&quot;, c(5L, 40L, 140L))) %&gt;%
  mutate(Iteration = seq_len(S)) %&gt;%
  gather(&quot;key&quot;, &quot;Value&quot;, select = -Iteration) %&gt;%
  ggplot(aes(x = Iteration, y = Value, color = &quot;1&quot;)) +
  geom_line(show.legend = FALSE) +
  theme_bw() +
  facet_wrap(~key, scales = &quot;free_y&quot;)</code></pre>
<p><img src="/post/2019-01-06-new-sblm-in-sbglm_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>For <code>$\beta_{40}$</code> and <code>$\beta_{140}$</code> there doesn’t seem to be any problem. We wouldn’t expect issues for the latter anyway, since it is not relevant for the model and therefore is updated using the prior. We do note that <code>$\beta_{5}$</code>, which is in the true model, exhibits again a random-walk behavior.</p>
<p>In order to dig deeper into this issue, we will construct a plot that focuses on the first group of variables <code>$(\beta_1,...,\beta_9)$</code>, by assessing the contribution that each of them make to their sum. The sum is a relevant quantity because the covariates they represent are almost exact copies, so it is meaningful to talk about a “total” effect arising from the group.</p>
<pre class="r"><code># colorblind palette
# http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
cbbPalette &lt;- c(&quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)

sel_beta = seq_len(nz_P %/% n_groups)
trace_beta = sapply(results, function(l){l$beta[sel_beta]})
trace_z = sapply(results, function(l){sel_beta %in% l$A})
t(trace_beta * trace_z) %&gt;%
  as.data.frame.matrix() %&gt;%
  setNames(sel_beta) %&gt;%
  mutate(Iteration = seq_len(S)) %&gt;%
  gather(&quot;key&quot;, &quot;Value&quot;, select = -Iteration) %&gt;%
  ggplot(aes(x = Iteration, y = Value, fill = key)) +
  geom_area(show.legend = FALSE) +
  geom_hline(yintercept = b_val * (nz_P %/% n_groups), linetype = &quot;dashed&quot;) +
  scale_fill_manual(name = &quot;&quot;, values = c(cbbPalette, &quot;navyblue&quot;)) +
  theme_bw()</code></pre>
<p><img src="/post/2019-01-06-new-sblm-in-sbglm_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Note how the sum total of the 9 components quickly approaches the expected value of 9 <code>$\times$</code> 3 <code>$=$</code> 27 (highlighted with the dashed line in the plot), and then stays very close to it. However, there is a sort of non-stationary dynamic in which the model never actually settles on any particular combination of the components. This is, of course, expected, given the extremely high correlation that the covariates within the group have. In other words, the sampler has a very good idea about where the total contribution of the group is, but it has a hard time inferring how to allocate this effect among the components, given the little data there is. In turn, because one coefficient gets assigned the effect of many others, the magnitudes of the components of <code>$\beta$</code> varies considerably, and this “confusion” propagates back to <code>$\sigma_b^2$</code> which explains its behavior.</p>
<p>The above phenomenon should not be unexpected, given the high within-group correlation and the fact that <code>$N \ll P$</code>. Even though the predictions of the model won’t be affected (the fact that <code>$\sigma_e^2$</code> is correctly recovered is evidence of this), one should always be cautious when interpreting the contributions of each variable to the response variable, given that the effects of highly correlated variables cannot be disentangled easily, especially with few data.</p>
<p>To finish this analysis, let us plot the posterior probability of each covariate being included in the model. The vertical line shows the limit for the active set:</p>
<pre class="r"><code>sapply(results[seq.int(S%/%2L+1L, S, 1L)], function(l){
  z=logical(P)
  z[l$A]=TRUE
  z
}) %&gt;%
  rowMeans() %&gt;%
  as.data.frame() %&gt;%
  setNames(c(&quot;prob&quot;)) %&gt;%
  mutate(Variable = seq_len(P)) %&gt;%
  ggplot(aes(x = Variable, y = prob)) +
  geom_line(show.legend = FALSE) +
  geom_vline(xintercept = nz_P, linetype = &quot;dotted&quot;) +
  theme_bw() +
  labs(y = &quot;Posterior probability of inclusion&quot;)</code></pre>
<p><img src="/post/2019-01-06-new-sblm-in-sbglm_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Given the symmetries present in the data, we would expect a uniform probability of inclusion of the first 45 variables (active set), and then close to 0 probability for the rest. The latter assumption holds almost perfectly, except for one variable at the end with a quite high probability of inclusion. On the other hand, we see a non-uniform probability of inclusion among the true relevant covariates, which is consistent with the problems previously described.</p>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>In this post I wanted to be a party-pooper, by fitting the sparse Bayesian linear regression to a terrible dataset, showing how it manages to work in some aspects, but fails to deliver in the most difficult ones. Even though this was obviously expected, it is important to stress how disconnected from the “reality” can the coefficients inferred from this type of data be. As always, it is good to know the limitations of our methods.</p>
<p>Feel free to leave a comment below!</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-griffiths2011indian">
<p>Griffiths, Thomas L, and Zoubin Ghahramani. 2011. “The Indian Buffet Process: An Introduction and Review.” <em>Journal of Machine Learning Research</em> 12 (Apr): 1185–1224.</p>
</div>
<div id="ref-lee2016exact">
<p>Lee, Jason D, Dennis L Sun, Yuekai Sun, Jonathan E Taylor, and others. 2016. “Exact Post-Selection Inference, with Application to the Lasso.” <em>The Annals of Statistics</em> 44 (3). Institute of Mathematical Statistics: 907–27.</p>
</div>
<div id="ref-tibshirani1996regression">
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>. JSTOR, 267–88.</p>
</div>
<div id="ref-zou2005regularization">
<p>Zou, Hui, and Trevor Hastie. 2005. “Regularization and Variable Selection via the Elastic Net.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 67 (2). Wiley Online Library: 301–20.</p>
</div>
</div>
</div>

        </p>
    </div>
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "the-mblog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    <div class="page-footer">
        <hr class="footer-divider">
        
        
            <a class="tag" href="/tags/bayesian">#bayesian</a>
        
            <a class="tag" href="/tags/sparse">#sparse</a>
        
            <a class="tag" href="/tags/linear-regression">#linear regression</a>
        
      
    </div>


        

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>


<script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>



<script src="/js/math-code.js"></script>


<script>
      renderMathInElement(
          document.body,
          {
              delimiters: [
                  {left: "$$", right: "$$", display: true},
                  {left: "\\[", right: "\\]", display: true},
                  {left: "$", right: "$", display: false},
                  {left: "\\(", right: "\\)", display: false}
              ]
          }
      );
</script>

        </div>
        <footer class="footer-mobile">
	<div class="social-icons">
        
    <a class="social-icon" href="mailto:miguel.biron@stat.ubc.ca" target="_blank" rel="noopener" title="Email">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M25.2794292,5.59128519 L14,16.8707144 L2.72057081,5.59128519 C3.06733103,5.30237414 3.51336915,5.12857603 4,5.12857603 L24,5.12857603 C24.4866308,5.12857603 24.932669,5.30237414 25.2794292,5.59128519 Z M25.9956978,6.99633695 C25.998551,7.04004843 26,7.08414302 26,7.12857603 L26,20.871424 C26,21.0798433 25.9681197,21.2808166 25.9089697,21.4697335 L18.7156355,14.2763993 L25.9956978,6.99633695 Z M24.9498374,22.6319215 C24.6672737,22.7846939 24.3437653,22.871424 24,22.871424 L4,22.871424 C3.5268522,22.871424 3.09207889,22.7071233 2.74962118,22.432463 L10.0950247,15.0870594 L13.9848068,18.9768415 L14.1878486,18.7737996 L14.2030419,18.7889929 L17.6549753,15.3370594 L24.9498374,22.6319215 Z M2.00810114,21.0526627 C2.00273908,20.9929669 2,20.9325153 2,20.871424 L2,7.12857603 C2,7.08414302 2.00144896,7.04004843 2.00430222,6.99633695 L9.03436454,14.0263993 L2.00810114,21.0526627 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    

    

    

    
    <a class="social-icon" href="https://linkedin.com/in/miguelbiron" target="_blank" rel="noopener" title="LinkedIn">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M2,3.654102 C2,2.69908141 2.79442509,1.92397846 3.77383592,1.92397846 L24.2261641,1.92397846 C25.2058917,1.92397846 26,2.69908141 26,3.654102 L26,24.3462148 C26,25.3015521 25.2058917,26.0760215 24.2261641,26.0760215 L3.77383592,26.0760215 C2.79442509,26.0760215 2,25.3015521 2,24.3465315 L2,3.65378524 L2,3.654102 Z M9.27526132,22.1415901 L9.27526132,11.2356668 L5.65030092,11.2356668 L5.65030092,22.1415901 L9.27557808,22.1415901 L9.27526132,22.1415901 Z M7.46341463,9.74691162 C8.72727273,9.74691162 9.51409566,8.90940767 9.51409566,7.86284447 C9.49033893,6.79252455 8.72727273,5.97846056 7.48748812,5.97846056 C6.24675325,5.97846056 5.43649034,6.79252455 5.43649034,7.86284447 C5.43649034,8.90940767 6.22299652,9.74691162 7.4396579,9.74691162 L7.46309788,9.74691162 L7.46341463,9.74691162 Z M11.2815965,22.1415901 L14.9062401,22.1415901 L14.9062401,16.0519481 C14.9062401,15.7263225 14.9299968,15.4000634 15.0256573,15.1675641 C15.2876148,14.5159962 15.8840672,13.8416218 16.8856509,13.8416218 C18.1970225,13.8416218 18.7218879,14.8416218 18.7218879,16.3078872 L18.7218879,22.1415901 L22.3465315,22.1415901 L22.3465315,15.8885017 C22.3465315,12.5388027 20.5584416,10.9800443 18.1735825,10.9800443 C16.2182452,10.9800443 15.3595185,12.072854 14.8824834,12.8172315 L14.9065569,12.8172315 L14.9065569,11.2359835 L11.2819132,11.2359835 C11.3291099,12.2591067 11.2815965,22.1419069 11.2815965,22.1419069 L11.2815965,22.1415901 Z"></path>
        </svg>
    </a>
    

    

    

    

    

    

    

    
    
    
    <a class="social-icon" href="https://github.com/miguelbiron" target="_blank" rel="noopener" title="GitHub">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M13.9988029,1.32087331 C6.82105037,1.32087331 1,7.14112562 1,14.3212723 C1,20.0649109 4.72454649,24.9370678 9.89038951,26.6560892 C10.5408085,26.7757983 10.7778323,26.374374 10.7778323,26.0296121 C10.7778323,25.7215609 10.7666595,24.9035493 10.760275,23.8189856 C7.14426471,24.6042767 6.38131925,22.0760223 6.38131925,22.0760223 C5.78995672,20.5740732 4.93762853,20.1742451 4.93762853,20.1742451 C3.75729765,19.3682044 5.02701126,19.3841656 5.02701126,19.3841656 C6.33183953,19.4759425 7.01817121,20.7241085 7.01817121,20.7241085 C8.17775254,22.7104801 10.0611744,22.1366749 10.8017741,21.8038838 C10.919887,20.9643246 11.2558703,20.3913175 11.6269683,20.066507 C8.74038491,19.7385043 5.70536235,18.6228163 5.70536235,13.6413251 C5.70536235,12.2223743 6.21213051,11.0611968 7.04370914,10.1530044 C6.90963504,9.82420367 6.46351945,8.50181809 7.17139875,6.71256734 C7.17139875,6.71256734 8.26234691,6.36301702 10.7459099,8.04532771 C11.78259,7.75642995 12.8950858,7.61277914 14.000399,7.60719272 C15.1049142,7.61277914 16.2166119,7.75642995 17.2548881,8.04532771 C19.736855,6.36301702 20.8262071,6.71256734 20.8262071,6.71256734 C21.5356825,8.50181809 21.0895669,9.82420367 20.9562909,10.1530044 C21.7894656,11.0611968 22.2922435,12.2223743 22.2922435,13.6413251 C22.2922435,18.6355852 19.2524325,19.734514 16.3570705,20.0561322 C16.8231376,20.4575564 17.2389269,21.2508282 17.2389269,22.4638795 C17.2389269,24.2012564 17.2229657,25.603448 17.2229657,26.0296121 C17.2229657,26.3775663 17.4575954,26.7821827 18.116793,26.6552912 C23.2786458,24.9322794 27,20.0633148 27,14.3212723 C27,7.14112562 21.1789496,1.32087331 13.9988029,1.32087331"></path>
        </svg>
    </a>
    

    
    <a class="social-icon" href="https://stackoverflow.com/users/5443023" target="_blank" rel="noopener" title="Stack Overflow">
        <svg width="28px" height="28px" viewBox="0 0 28 28" version="1.1" fill="#ABABAB" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
            <path d="M20.8863636,23.7090909 L20.8863636,17.3818182 L22.9863636,17.3818182 L22.9863636,25.8090909 L4.03181818,25.8090909 L4.03181818,17.3818182 L6.13181818,17.3818182 L6.13181818,23.7090909 L20.8863636,23.7090909 Z M8.45,16.7818182 L8.88636364,14.7090909 L19.1954545,16.8636364 L18.7590909,18.9363636 L8.45,16.7818182 Z M9.81363636,11.8727273 L10.6863636,9.93636364 L20.2318182,14.4090909 L19.3590909,16.3181818 L9.81363636,11.8727273 Z M12.4590909,7.18181818 L13.7954545,5.57272727 L21.8954545,12.3090909 L20.5590909,13.9181818 L12.4590909,7.18181818 Z M17.6954545,2.19090909 L23.9681818,10.6454545 L22.2772727,11.9 L16.0045455,3.44545455 L17.6954545,2.19090909 Z M8.23181818,21.5818182 L8.23181818,19.4818182 L18.7590909,19.4818182 L18.7590909,21.5818182 L8.23181818,21.5818182 Z"></path>
        </svg>
    </a>
    
    
    

    
</div>




	<div class="footer-mobile-links">
		<p><a href="https://github.com/kimcc/hugo-theme-noteworthy" target="_blank" rel="noopener">Noteworthy theme</a></p>
		<span class="divider-bar">|</span>
		<p><a href="https://gohugo.io" target="_blank" rel="noopener">Built with Hugo</a></p>
	</div>

	<script src="/js/main.min.fa5c2b23e07b5d9bfad267a52b4b24fdb053e6fb7524993383594926a3ac270c.js" integrity="sha256-+lwrI+B7XZv60melK0sk/bBT5vt1JJkzg1lJJqOsJww="></script>
</footer>
    </body>
</html>